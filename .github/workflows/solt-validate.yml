# =============================================================================
# SOLT PRE-COMMIT - Reusable Workflow
# =============================================================================
name: Solt Validation (Reusable)

on:
  workflow_call:
    inputs:
      python-version:
        description: 'Python version to use'
        required: false
        type: string
        default: '3.11'
      odoo-version:
        description: 'Odoo version (for compatibility checks)'
        required: false
        type: string
        default: '17.0'
      validation-scope:
        description: 'Validation scope: changed or full'
        required: false
        type: string
        default: 'changed'
      run-coverage:
        description: 'Run coverage analysis'
        required: false
        type: boolean
        default: false
      coverage-threshold:
        description: 'Minimum coverage percentage'
        required: false
        type: number
        default: 60
      fail-on-warnings:
        description: 'Fail if warnings are found'
        required: false
        type: boolean
        default: false
      show-info:
        description: 'Show info-level issues in report'
        required: false
        type: boolean
        default: false
      gist-id:
        description: 'Gist ID for badge storage (optional)'
        required: false
        type: string
        default: ''
      badge-filename-prefix:
        description: 'Prefix for badge filenames in gist (e.g., solt-budget)'
        required: false
        type: string
        default: ''
      docstring-threshold:
        description: 'Minimum docstring coverage to pass (default: 80)'
        required: false
        type: number
        default: 80
    secrets:
      GIST_SECRET:
        description: 'GitHub token for updating gist badges'
        required: false
    outputs:
      validation-result:
        description: 'Validation result (success/failure)'
        value: ${{ jobs.validate.outputs.result }}
      errors-count:
        description: 'Number of errors found'
        value: ${{ jobs.validate.outputs.errors }}
      warnings-count:
        description: 'Number of warnings found'
        value: ${{ jobs.validate.outputs.warnings }}
      docstring-coverage:
        description: 'Docstring coverage percentage'
        value: ${{ jobs.validate.outputs.docstring_cov }}

jobs:
  # ---------------------------------------------------------------------------
  # BRANCH VALIDATION
  # ---------------------------------------------------------------------------
  branch-check:
    name: Branch Name
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python-version }}
      - name: Install solt-pre-commit
        run: pip install "git+https://github.com/soltein-net/solt-pre-commit.git@v1.0.0"
      - name: Validate branch name
        run: |
          BRANCH="${{ github.head_ref }}"
          echo "## Branch Validation" >> $GITHUB_STEP_SUMMARY
          echo "Branch: \`$BRANCH\`" >> $GITHUB_STEP_SUMMARY
          if solt-check-branch "$BRANCH"; then
            echo "Branch name is valid" >> $GITHUB_STEP_SUMMARY
          else
            echo "Branch name is invalid" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

  # ---------------------------------------------------------------------------
  # MAIN VALIDATION
  # ---------------------------------------------------------------------------
  validate:
    name: Odoo Module Validation
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    outputs:
      result: ${{ steps.summary.outputs.result }}
      errors: ${{ steps.summary.outputs.errors }}
      warnings: ${{ steps.summary.outputs.warnings }}
      docstring_cov: ${{ steps.metrics.outputs.docstring_cov }}
      docs_status: ${{ steps.metrics.outputs.docs_status }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install "git+https://github.com/soltein-net/solt-pre-commit.git@v1.0.0"
          pip install pylint-odoo ruff

      - name: Find Odoo modules
        id: find-modules
        run: |
          MODULES=$(find . -name "__manifest__.py" -o -name "__openerp__.py" | xargs -I {} dirname {} | sort -u | tr '\n' ' ')
          MODULE_COUNT=$(echo "$MODULES" | wc -w | tr -d ' ')
          if [ -z "$MODULE_COUNT" ] || [ "$MODULE_COUNT" = "" ]; then
            MODULE_COUNT=0
          fi
          echo "modules=$MODULES" >> $GITHUB_OUTPUT
          echo "count=$MODULE_COUNT" >> $GITHUB_OUTPUT
          echo "Found $MODULE_COUNT modules: $MODULES"

      - name: Run validation (changed files)
        id: validate
        run: |
          mkdir -p reports
          ARGS="--scope ${{ inputs.validation-scope }}"
          if [ "${{ inputs.show-info }}" = "true" ]; then
            ARGS="$ARGS --show-info"
          fi
          
          set +e
          START_TIME=$(date +%s)
          solt-check-odoo ${{ steps.find-modules.outputs.modules }} $ARGS 2>&1 | tee reports/validation.txt
          EXIT_CODE=$?
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          set -e

          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          echo "duration=$DURATION" >> $GITHUB_OUTPUT

      - name: Run full validation for metrics
        run: |
          solt-check-odoo ${{ steps.find-modules.outputs.modules }} --scope full --show-info 2>&1 | tee reports/validation-full.txt || true

      - name: Run Ruff check
        id: ruff
        continue-on-error: true
        run: |
          set +e
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            git fetch origin ${{ github.base_ref }} --depth=1 2>/dev/null || true
            CHANGED_PY=$(git diff --name-only origin/${{ github.base_ref }}...HEAD -- '*.py' 2>/dev/null | tr '\n' ' ')
          else
            CHANGED_PY=$(git diff --name-only HEAD~1...HEAD -- '*.py' 2>/dev/null | tr '\n' ' ')
          fi
          
          RUFF_CHANGED=0
          if [ -n "$CHANGED_PY" ]; then
            ruff check $CHANGED_PY --output-format=concise 2>&1 | tee reports/ruff-changed.txt || true
            RUFF_CHANGED=$(grep -cE "^.+:[0-9]+:[0-9]+:" reports/ruff-changed.txt 2>/dev/null || echo 0)
          fi
          
          ruff check ${{ steps.find-modules.outputs.modules }} --output-format=concise 2>&1 | tee reports/ruff-full.txt || true
          RUFF_FULL=$(grep -cE "^.+:[0-9]+:[0-9]+:" reports/ruff-full.txt 2>/dev/null || echo 0)
          
          RUFF_CHANGED=$(echo "$RUFF_CHANGED" | grep -oE '^[0-9]+' || echo 0)
          RUFF_FULL=$(echo "$RUFF_FULL" | grep -oE '^[0-9]+' || echo 0)
          
          echo "changed=${RUFF_CHANGED:-0}" >> $GITHUB_OUTPUT
          echo "full=${RUFF_FULL:-0}" >> $GITHUB_OUTPUT

      - name: Run Pylint-Odoo check
        id: pylint
        continue-on-error: true
        run: |
          set +e
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            CHANGED_PY=$(git diff --name-only origin/${{ github.base_ref }}...HEAD -- '*.py' 2>/dev/null | tr '\n' ' ')
          else
            CHANGED_PY=$(git diff --name-only HEAD~1...HEAD -- '*.py' 2>/dev/null | tr '\n' ' ')
          fi
          
          PYLINT_CHANGED=0
          if [ -n "$CHANGED_PY" ]; then
            echo "$CHANGED_PY" | xargs pylint --load-plugins=pylint_odoo --exit-zero 2>&1 | tee reports/pylint-changed.txt || true
            PYLINT_CHANGED=$(grep -cE "^[CRWEF][0-9]{4}:" reports/pylint-changed.txt 2>/dev/null || echo 0)
          fi
          
          find ${{ steps.find-modules.outputs.modules }} -name "*.py" -not -path "*/__pycache__/*" 2>/dev/null | head -100 | xargs pylint --load-plugins=pylint_odoo --exit-zero 2>&1 | tee reports/pylint-full.txt || true
          PYLINT_FULL=$(grep -cE "^[CRWEF][0-9]{4}:" reports/pylint-full.txt 2>/dev/null || echo 0)
          
          PYLINT_CHANGED=$(echo "$PYLINT_CHANGED" | grep -oE '^[0-9]+' || echo 0)
          PYLINT_FULL=$(echo "$PYLINT_FULL" | grep -oE '^[0-9]+' || echo 0)
          
          echo "changed=${PYLINT_CHANGED:-0}" >> $GITHUB_OUTPUT
          echo "full=${PYLINT_FULL:-0}" >> $GITHUB_OUTPUT

      - name: Calculate real metrics
        id: metrics
        env:
          DOCSTRING_THRESHOLD: ${{ inputs.docstring-threshold }}
        run: |
          python3 << 'EOF'
          import os
          import re
          import json

          metrics_data = {
              'docstring_cov': 0, 'docstring_documented': 0, 'docstring_total': 1,
              'string_cov': 0, 'string_documented': 0, 'string_total': 1,
              'help_cov': 0, 'help_documented': 0, 'help_total': 1,
              'models': 0
          }

          try:
              with open('reports/validation-full.txt', 'r') as f:
                  content = f.read()
              metrics_match = re.search(r'^METRICS:(.+)$', content, re.MULTILINE)
              if metrics_match:
                  for pair in metrics_match.group(1).split(','):
                      if '=' in pair:
                          key, value = pair.split('=', 1)
                          try:
                              metrics_data[key.strip()] = float(value) if '.' in value else int(value)
                          except ValueError:
                              pass
          except FileNotFoundError:
              print("Warning: validation-full.txt not found")

          missing_docstring_pr = missing_string_pr = missing_help_pr = 0
          try:
              with open('reports/validation.txt', 'r') as f:
                  pr_content = f.read().lower()
              missing_docstring_pr = pr_content.count('missing docstring')
              missing_string_pr = pr_content.count('missing string')
              missing_help_pr = pr_content.count('missing help')
          except FileNotFoundError:
              pass

          docstring_cov = metrics_data.get('docstring_cov', 0)
          threshold = int(os.environ.get('DOCSTRING_THRESHOLD', 80))
          docs_status = 'passing' if docstring_cov >= threshold else 'failing'

          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"docstring_cov={int(docstring_cov)}\n")
              f.write(f"docstring_documented={int(metrics_data.get('docstring_documented', 0))}\n")
              f.write(f"docstring_total={int(metrics_data.get('docstring_total', 1))}\n")
              f.write(f"string_cov={int(metrics_data.get('string_cov', 0))}\n")
              f.write(f"string_documented={int(metrics_data.get('string_documented', 0))}\n")
              f.write(f"string_total={int(metrics_data.get('string_total', 1))}\n")
              f.write(f"help_cov={int(metrics_data.get('help_cov', 0))}\n")
              f.write(f"help_documented={int(metrics_data.get('help_documented', 0))}\n")
              f.write(f"help_total={int(metrics_data.get('help_total', 1))}\n")
              f.write(f"models={int(metrics_data.get('models', 0))}\n")
              f.write(f"missing_docstring_pr={missing_docstring_pr}\n")
              f.write(f"missing_string_pr={missing_string_pr}\n")
              f.write(f"missing_help_pr={missing_help_pr}\n")
              f.write(f"docs_status={docs_status}\n")

          with open('reports/metrics.json', 'w') as f:
              json.dump(metrics_data, f, indent=2)

          print(f"Docstrings: {docstring_cov:.1f}% | Status: {docs_status}")
          EOF

          echo "ruff_changed=${{ steps.ruff.outputs.changed }}" >> $GITHUB_OUTPUT
          echo "ruff_full=${{ steps.ruff.outputs.full }}" >> $GITHUB_OUTPUT
          echo "pylint_changed=${{ steps.pylint.outputs.changed }}" >> $GITHUB_OUTPUT
          echo "pylint_full=${{ steps.pylint.outputs.full }}" >> $GITHUB_OUTPUT

      - name: Generate summary
        id: summary
        run: |
          EXIT_CODE="${{ steps.validate.outputs.exit_code }}"
          EXIT_CODE=$(echo "$EXIT_CODE" | grep -oE '^[0-9]+' || echo 0)
          if [ -z "$EXIT_CODE" ]; then EXIT_CODE=0; fi
          
          if [ "$EXIT_CODE" -ne 0 ]; then
            RESULT="failure"
          else
            RESULT="success"
          fi
          
          ERRORS=$(grep -ciE "error" reports/validation.txt 2>/dev/null || echo 0)
          WARNINGS=$(grep -ciE "warning" reports/validation.txt 2>/dev/null || echo 0)
          
          echo "result=$RESULT" >> $GITHUB_OUTPUT
          echo "errors=$ERRORS" >> $GITHUB_OUTPUT
          echo "warnings=$WARNINGS" >> $GITHUB_OUTPUT

      - name: Upload reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: validation-reports
          path: reports/
          retention-days: 7

      - name: Comment PR with report
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        env:
          MODULE_COUNT: ${{ steps.find-modules.outputs.count }}
          EXIT_CODE: ${{ steps.validate.outputs.exit_code }}
          DURATION: ${{ steps.validate.outputs.duration }}
          SCOPE: ${{ inputs.validation-scope }}
          DOCSTRING_COV: ${{ steps.metrics.outputs.docstring_cov }}
          DOCSTRING_DOCUMENTED: ${{ steps.metrics.outputs.docstring_documented }}
          DOCSTRING_TOTAL: ${{ steps.metrics.outputs.docstring_total }}
          STRING_COV: ${{ steps.metrics.outputs.string_cov }}
          STRING_DOCUMENTED: ${{ steps.metrics.outputs.string_documented }}
          STRING_TOTAL: ${{ steps.metrics.outputs.string_total }}
          HELP_COV: ${{ steps.metrics.outputs.help_cov }}
          HELP_DOCUMENTED: ${{ steps.metrics.outputs.help_documented }}
          HELP_TOTAL: ${{ steps.metrics.outputs.help_total }}
          MISSING_DOCSTRING_PR: ${{ steps.metrics.outputs.missing_docstring_pr }}
          MISSING_STRING_PR: ${{ steps.metrics.outputs.missing_string_pr }}
          MISSING_HELP_PR: ${{ steps.metrics.outputs.missing_help_pr }}
          RUFF_CHANGED: ${{ steps.metrics.outputs.ruff_changed }}
          RUFF_FULL: ${{ steps.metrics.outputs.ruff_full }}
          PYLINT_CHANGED: ${{ steps.metrics.outputs.pylint_changed }}
          PYLINT_FULL: ${{ steps.metrics.outputs.pylint_full }}
          DOCSTRING_THRESHOLD: ${{ inputs.docstring-threshold }}
        with:
          script: |
            function safeInt(val, def = 0) {
              const parsed = parseInt(val);
              return isNaN(parsed) ? def : parsed;
            }
            
            const moduleCount = safeInt(process.env.MODULE_COUNT);
            const exitCode = safeInt(process.env.EXIT_CODE);
            const duration = safeInt(process.env.DURATION);
            const scope = process.env.SCOPE;
            const threshold = safeInt(process.env.DOCSTRING_THRESHOLD, 80);
            
            const docstringCov = safeInt(process.env.DOCSTRING_COV);
            const documentedMethods = safeInt(process.env.DOCSTRING_DOCUMENTED);
            const totalMethods = safeInt(process.env.DOCSTRING_TOTAL, 1);
            
            const stringCov = safeInt(process.env.STRING_COV);
            const fieldsWithString = safeInt(process.env.STRING_DOCUMENTED);
            const totalFields = safeInt(process.env.STRING_TOTAL, 1);
            
            const helpCov = safeInt(process.env.HELP_COV);
            const fieldsWithHelp = safeInt(process.env.HELP_DOCUMENTED);
            const helpTotal = safeInt(process.env.HELP_TOTAL, 1);
            
            const missingDocstringPr = safeInt(process.env.MISSING_DOCSTRING_PR);
            const missingStringPr = safeInt(process.env.MISSING_STRING_PR);
            const missingHelpPr = safeInt(process.env.MISSING_HELP_PR);
            
            const ruffChanged = safeInt(process.env.RUFF_CHANGED);
            const ruffFull = safeInt(process.env.RUFF_FULL);
            const pylintChanged = safeInt(process.env.PYLINT_CHANGED);
            const pylintFull = safeInt(process.env.PYLINT_FULL);
            
            function icon(val, th, reverse = false) {
              if (reverse) return val <= th ? ':white_check_mark:' : ':x:';
              return val >= th ? ':white_check_mark:' : ':warning:';
            }
            
            const overallStatus = exitCode === 0 ? ':white_check_mark: Passed' : ':x: Failed';
            
            const body = [
              '## :bar_chart: Reporte de Validacion',
              '',
              '> :information_source: Este analisis es **informativo**.',
              '',
              '### :clipboard: Resumen',
              '',
              '| Metrica | Valor |',
              '|---------|-------|',
              `| **Estado** | ${overallStatus} |`,
              `| Modulos | ${moduleCount} |`,
              `| Scope | \`${scope}\` |`,
              `| Tiempo | ${duration}s |`,
              '',
              '### :books: Cobertura de Documentacion',
              '',
              '| Metrica | Cobertura | Detalle | Meta | Estado |',
              '|---------|-----------|---------|------|--------|',
              `| Docstrings | **${docstringCov}%** | ${documentedMethods}/${totalMethods} | >=${threshold}% | ${icon(docstringCov, threshold)} |`,
              `| Campos string | **${stringCov}%** | ${fieldsWithString}/${totalFields} | >=90% | ${icon(stringCov, 90)} |`,
              `| Campos help | **${helpCov}%** | ${fieldsWithHelp}/${helpTotal} | >=50% | ${icon(helpCov, 50)} |`,
              '',
              '### :warning: Issues en este PR',
              '',
              '| Tipo | Cantidad |',
              '|------|----------|',
              `| Docstrings faltantes | ${missingDocstringPr} |`,
              `| Campos sin string | ${missingStringPr} |`,
              `| Campos sin help | ${missingHelpPr} |`,
              '',
              '### :mag: Calidad de Codigo',
              '',
              '| Herramienta | PR | Repo | Estado |',
              '|-------------|----|------|--------|',
              `| Ruff | ${ruffChanged} | ${ruffFull} | ${icon(ruffFull, 0, true)} |`,
              `| Pylint | ${pylintChanged} | ${pylintFull} | ${icon(pylintFull, 0, true)} |`,
              '',
              '---',
              ':robot: *solt-pre-commit*'
            ].join('\n');
            
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(c => 
              c.user.type === 'Bot' && c.body.includes('Reporte de Validacion')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

      - name: Check result
        run: |
          RESULT="${{ steps.summary.outputs.result }}"
          if [ -z "$RESULT" ]; then RESULT="success"; fi
          if [ "$RESULT" = "failure" ]; then
            echo "::error::Validation failed"
            exit 1
          fi

  # ---------------------------------------------------------------------------
  # UPDATE BADGES (on push to protected branches)
  # ---------------------------------------------------------------------------
  update-badges:
    name: Update Documentation Badges
    runs-on: ubuntu-latest
    needs: validate
    if: |
      github.event_name == 'push' && 
      (github.ref == 'refs/heads/main' || 
       github.ref == 'refs/heads/master' || 
       github.ref == 'refs/heads/develop' || 
       startsWith(github.ref, 'refs/heads/17.0') || 
       startsWith(github.ref, 'refs/heads/18.0'))

    steps:
      - name: Update docstrings badge
        if: inputs.gist-id != ''
        uses: schneegans/dynamic-badges-action@v1.7.0
        continue-on-error: true
        with:
          auth: ${{ secrets.GIST_SECRET }}
          gistID: ${{ inputs.gist-id }}
          filename: ${{ inputs.badge-filename-prefix }}-docstrings.json
          label: docstrings
          message: "${{ needs.validate.outputs.docstring_cov }}%"
          valColorRange: ${{ needs.validate.outputs.docstring_cov }}
          minColorRange: 0
          maxColorRange: 100
          namedLogo: python
          logoColor: white

      - name: Update docs status badge
        if: inputs.gist-id != ''
        uses: schneegans/dynamic-badges-action@v1.7.0
        continue-on-error: true
        with:
          auth: ${{ secrets.GIST_SECRET }}
          gistID: ${{ inputs.gist-id }}
          filename: ${{ inputs.badge-filename-prefix }}-docs-status.json
          label: Documentation Standards
          message: ${{ needs.validate.outputs.docs_status }}
          color: ${{ needs.validate.outputs.docs_status == 'passing' && 'brightgreen' || 'red' }}
          namedLogo: github
          logoColor: white

  # ---------------------------------------------------------------------------
  # PRE-COMMIT HOOKS
  # ---------------------------------------------------------------------------
  pre-commit:
    name: Pre-commit Hooks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python-version }}

      - name: Install pre-commit
        run: pip install pre-commit

      - name: Get changed files
        id: changed
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            git fetch origin ${{ github.base_ref }} --depth=1
            CHANGED_FILES=$(git diff --name-only origin/${{ github.base_ref }}...HEAD | tr '\n' ' ')
          else
            CHANGED_FILES=$(git diff --name-only HEAD~1...HEAD 2>/dev/null | tr '\n' ' ')
          fi
          
          VALID_FILES=""
          for f in $CHANGED_FILES; do
            if [ -f "$f" ]; then
              VALID_FILES="$VALID_FILES $f"
            fi
          done
          VALID_FILES=$(echo "$VALID_FILES" | xargs)
          
          FILE_COUNT=$(echo "$VALID_FILES" | wc -w | tr -d ' ')
          if [ -z "$FILE_COUNT" ]; then FILE_COUNT=0; fi
          
          echo "files=$VALID_FILES" >> $GITHUB_OUTPUT
          echo "count=$FILE_COUNT" >> $GITHUB_OUTPUT

      - name: Run pre-commit
        id: precommit
        run: |
          FILES="${{ steps.changed.outputs.files }}"
          COUNT="${{ steps.changed.outputs.count }}"
          if [ -z "$COUNT" ]; then COUNT=0; fi
          
          if [ -z "$FILES" ] || [ "$COUNT" = "0" ]; then
            echo "No files to check"
            echo "status=skipped" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "Checking $COUNT files..."
          if pre-commit run --files $FILES 2>&1 | tee precommit_output.txt; then
            echo "status=passed" >> $GITHUB_OUTPUT
          else
            echo "status=failed" >> $GITHUB_OUTPUT
            exit 1
          fi

      - name: Summary
        if: always()
        run: |
          echo "## Pre-commit Hooks" >> $GITHUB_STEP_SUMMARY
          echo "Files checked: ${{ steps.changed.outputs.count }}" >> $GITHUB_STEP_SUMMARY
          STATUS="${{ steps.precommit.outputs.status }}"
          if [ "$STATUS" = "passed" ]; then
            echo "All hooks passed" >> $GITHUB_STEP_SUMMARY
          elif [ "$STATUS" = "skipped" ]; then
            echo "No files to check" >> $GITHUB_STEP_SUMMARY
          else
            echo "Some hooks failed" >> $GITHUB_STEP_SUMMARY
          fi

  # ---------------------------------------------------------------------------
  # COVERAGE ANALYSIS (Optional)
  # ---------------------------------------------------------------------------
  coverage:
    name: Coverage Analysis
    runs-on: ubuntu-latest
    if: inputs.run-coverage
    needs: validate
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python-version }}

      - name: Run coverage
        id: coverage
        continue-on-error: true
        run: |
          pip install coverage pytest pytest-cov
          mkdir -p reports
          COVERAGE=0
          if [ -d "tests" ]; then
            coverage run -m pytest tests/ -v --tb=short 2>&1 | tee reports/test_output.txt || true
            coverage report -m | tee reports/coverage.txt || true
            COVERAGE=$(tail -1 reports/coverage.txt 2>/dev/null | awk '{print $NF}' | grep -oE '[0-9]+' | head -1 || echo 0)
          fi
          if [ -z "$COVERAGE" ]; then COVERAGE=0; fi
          echo "percentage=$COVERAGE" >> $GITHUB_OUTPUT

      - name: Check threshold
        run: |
          COV="${{ steps.coverage.outputs.percentage }}"
          THRESHOLD="${{ inputs.coverage-threshold }}"
          COV=$(echo "$COV" | grep -oE '[0-9]+' | head -1 || echo 0)
          THRESHOLD=$(echo "$THRESHOLD" | grep -oE '[0-9]+' | head -1 || echo 60)
          if [ -z "$COV" ]; then COV=0; fi
          if [ -z "$THRESHOLD" ]; then THRESHOLD=60; fi
          echo "## Coverage: ${COV}%" >> $GITHUB_STEP_SUMMARY
          if [ "$COV" -ne 0 ] && [ "$COV" -lt "$THRESHOLD" ]; then
            echo "::error::Coverage ${COV}% < ${THRESHOLD}%"
            exit 1
          fi